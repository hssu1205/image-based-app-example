import streamlit as st
from deepface import DeepFace
import cv2
import numpy as np
from PIL import Image
import tempfile
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê°ì • ì¸ì‹ ì•±",
    page_icon="ğŸ˜Š",
    layout="wide"
)

# ê°ì •ë³„ ì´ëª¨ì§€ ë° í”¼ë“œë°± ë©”ì‹œì§€
EMOTION_FEEDBACK = {
    'happy': {
        'emoji': 'ğŸ˜Š',
        'name': 'í–‰ë³µ',
        'message': 'í–‰ë³µí•´ ë³´ì´ì‹œë„¤ìš”! ê¸ì •ì ì¸ ì—ë„ˆì§€ê°€ ëŠê»´ì§‘ë‹ˆë‹¤.',
        'color': '#FFD700'
    },
    'sad': {
        'emoji': 'ğŸ˜¢',
        'name': 'ìŠ¬í””',
        'message': 'ìŠ¬í¼ ë³´ì´ì‹œë„¤ìš”. í˜ë‚´ì„¸ìš”! ì¢‹ì€ ì¼ì´ ìƒê¸¸ ê±°ì˜ˆìš”.',
        'color': '#4169E1'
    },
    'angry': {
        'emoji': 'ğŸ˜ ',
        'name': 'í™”ë‚¨',
        'message': 'í™”ê°€ ë‚˜ ë³´ì´ì‹œë„¤ìš”. ì‹¬í˜¸í¡ì„ í•˜ê³  ì§„ì •í•˜ì„¸ìš”.',
        'color': '#DC143C'
    },
    'surprise': {
        'emoji': 'ğŸ˜²',
        'name': 'ë†€ëŒ',
        'message': 'ë†€ë¼ì‹  ê²ƒ ê°™ë„¤ìš”! ë¬´ìŠ¨ ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”?',
        'color': '#FF8C00'
    },
    'fear': {
        'emoji': 'ğŸ˜¨',
        'name': 'ë‘ë ¤ì›€',
        'message': 'ë‘ë ¤ì›Œ ë³´ì´ì‹œë„¤ìš”. ê´œì°®ìœ¼ì‹¤ ê±°ì˜ˆìš”.',
        'color': '#9370DB'
    },
    'disgust': {
        'emoji': 'ğŸ¤¢',
        'name': 'í˜ì˜¤',
        'message': 'ë¶ˆì¾Œí•´ ë³´ì´ì‹œë„¤ìš”. ê¸°ë¶„ ì „í™˜ì´ í•„ìš”í•  ê²ƒ ê°™ì•„ìš”.',
        'color': '#228B22'
    },
    'neutral': {
        'emoji': 'ğŸ˜',
        'name': 'ë¬´í‘œì •',
        'message': 'í‰ì˜¨í•œ ìƒíƒœì‹œë„¤ìš”. ì•ˆì •ì ì¸ ê°ì • ìƒíƒœì…ë‹ˆë‹¤.',
        'color': '#808080'
    }
}

def analyze_emotion(image):
    """ì´ë¯¸ì§€ì—ì„œ ê°ì • ë¶„ì„"""
    try:
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        img_array = np.array(image)
        
        # RGB to BGR (OpenCV format)
        if len(img_array.shape) == 3 and img_array.shape[2] == 3:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
            cv2.imwrite(tmp_file.name, img_array)
            tmp_path = tmp_file.name
        
        try:
            # DeepFaceë¡œ ê°ì • ë¶„ì„
            result = DeepFace.analyze(
                img_path=tmp_path,
                actions=['emotion'],
                enforce_detection=False,
                detector_backend='opencv'
            )
            
            # ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
            if isinstance(result, list):
                result = result[0]
            
            return result
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
                
    except Exception as e:
        st.error(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def display_emotion_result(result):
    """ê°ì • ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    if result is None:
        return
    
    emotions = result.get('emotion', {})
    dominant_emotion = result.get('dominant_emotion', 'neutral')
    
    # ê°ì •ë³„ í”¼ë“œë°± ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    feedback = EMOTION_FEEDBACK.get(dominant_emotion, EMOTION_FEEDBACK['neutral'])
    
    # ì£¼ìš” ê°ì • í‘œì‹œ
    st.markdown(f"### {feedback['emoji']} ì£¼ìš” ê°ì •: **{feedback['name']}**")
    st.markdown(f"<p style='color: {feedback['color']}; font-size: 18px;'>{feedback['message']}</p>", 
                unsafe_allow_html=True)
    
    # ëª¨ë“  ê°ì • í™•ë¥  í‘œì‹œ
    st.markdown("---")
    st.subheader("ğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼")
    
    # ê°ì •ì„ í™•ë¥  ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_emotions = sorted(emotions.items(), key=lambda x: x[1], reverse=True)
    
    for emotion, score in sorted_emotions:
        col1, col2 = st.columns([1, 4])
        with col1:
            emotion_info = EMOTION_FEEDBACK.get(emotion, {})
            emoji = emotion_info.get('emoji', 'ğŸ˜¶')
            name = emotion_info.get('name', emotion)
            st.write(f"{emoji} {name}")
        with col2:
            st.progress(float(score) / 100)
            st.caption(f"{score:.2f}%")

# ì•± ì œëª©
st.title("ğŸ˜Š ê°ì • ì¸ì‹ ì•±")
st.markdown("ì–¼êµ´ ì‚¬ì§„ì„ í†µí•´ ê°ì •ì„ ë¶„ì„í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.")

# íƒ­ ìƒì„±
tab1, tab2 = st.tabs(["ğŸ“· ì¹´ë©”ë¼ë¡œ ì´¬ì˜", "ğŸ“ ì´ë¯¸ì§€ ì—…ë¡œë“œ"])

# ì¹´ë©”ë¼ íƒ­
with tab1:
    st.subheader("ì¹´ë©”ë¼ë¡œ ì–¼êµ´ ì‚¬ì§„ ì´¬ì˜")
    st.info("ì¹´ë©”ë¼ë¥¼ í™œì„±í™”í•˜ê³  ì´¬ì˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'camera_captured' not in st.session_state:
        st.session_state.camera_captured = False
    if 'show_camera' not in st.session_state:
        st.session_state.show_camera = False
    
    # ì¹´ë©”ë¼ í™œì„±í™” ë²„íŠ¼
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
    with col_btn1:
        if st.button("ğŸ“· ì¹´ë©”ë¼ ì¼œê¸°", use_container_width=True):
            st.session_state.show_camera = True
            st.session_state.camera_captured = False
    with col_btn2:
        if st.button("âŒ ì¹´ë©”ë¼ ë„ê¸°", use_container_width=True):
            st.session_state.show_camera = False
            st.session_state.camera_captured = False
    
    # ì¹´ë©”ë¼ ì…ë ¥
    if st.session_state.show_camera:
        camera_photo = st.camera_input("ì‚¬ì§„ ì´¬ì˜")
        
        if camera_photo is not None:
            # ì´ë¯¸ì§€ ì—´ê¸°
            image = Image.open(camera_photo)
            
            # ê°ì • ë¶„ì„ ë²„íŠ¼
            if st.button("ğŸ” ê°ì • ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True):
                st.session_state.camera_captured = True
            
            if st.session_state.camera_captured:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.image(image, caption="ì´¬ì˜ëœ ì´ë¯¸ì§€", use_container_width=True)
                
                with col2:
                    with st.spinner("ê°ì • ë¶„ì„ ì¤‘..."):
                        result = analyze_emotion(image)
                        if result:
                            display_emotion_result(result)

# ì´ë¯¸ì§€ ì—…ë¡œë“œ íƒ­
with tab2:
    st.subheader("ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ")
    st.info("JPG, JPEG, PNG í˜•ì‹ì˜ ì–¼êµ´ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    uploaded_file = st.file_uploader(
        "ì´ë¯¸ì§€ ì„ íƒ",
        type=['jpg', 'jpeg', 'png'],
        help="ì–¼êµ´ì´ í¬í•¨ëœ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )
    
    if uploaded_file is not None:
        # ì´ë¯¸ì§€ ì—´ê¸°
        image = Image.open(uploaded_file)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
        
        with col2:
            with st.spinner("ê°ì • ë¶„ì„ ì¤‘..."):
                result = analyze_emotion(image)
                if result:
                    display_emotion_result(result)

# ì‚¬ì´ë“œë°” ì •ë³´
with st.sidebar:
    st.header("â„¹ï¸ ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. **ì¹´ë©”ë¼ë¡œ ì´¬ì˜** ë˜ëŠ” **ì´ë¯¸ì§€ ì—…ë¡œë“œ** íƒ­ì„ ì„ íƒí•˜ì„¸ìš”.
    2. ì–¼êµ´ì´ ì˜ ë³´ì´ë„ë¡ ì‚¬ì§„ì„ ì´¬ì˜í•˜ê±°ë‚˜ ì—…ë¡œë“œí•˜ì„¸ìš”.
    3. ìë™ìœ¼ë¡œ ê°ì •ì´ ë¶„ì„ë˜ê³  ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.
    
    ---
    
    ### ì¸ì‹ ê°€ëŠ¥í•œ ê°ì •
    - ğŸ˜Š í–‰ë³µ (Happy)
    - ğŸ˜¢ ìŠ¬í”” (Sad)
    - ğŸ˜  í™”ë‚¨ (Angry)
    - ğŸ˜² ë†€ëŒ (Surprise)
    - ğŸ˜¨ ë‘ë ¤ì›€ (Fear)
    - ğŸ¤¢ í˜ì˜¤ (Disgust)
    - ğŸ˜ ë¬´í‘œì • (Neutral)
    
    ---
    
    ### ğŸ“ íŒ
    - ì–¼êµ´ì´ ì •ë©´ì„ í–¥í•˜ë„ë¡ ì´¬ì˜í•˜ì„¸ìš”
    - ì¡°ëª…ì´ ì ì ˆí•œ í™˜ê²½ì—ì„œ ì´¬ì˜í•˜ì„¸ìš”
    - ì–¼êµ´ì´ ê°€ë ¤ì§€ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”
    """)
    
    st.markdown("---")
    st.caption("Powered by DeepFace & Streamlit")

